{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3622d34c-dd6f-410d-8196-f5884bd7836a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Snowpark For Python\n",
    "\n",
    "### In this session, we will cover:\n",
    "\n",
    "* Creating Session object and connecting to Snowflake\n",
    "* Reading and loading data from Snowflake table into Snowpark DataFrame\n",
    "* Perfoming Exploratory Data Analysis (EDA) on Snowpark DataFrame\n",
    "* Creating User-Defined Function (UDF) -- with dependencies\n",
    "* Using pre-trained scikit-learn model for inference in UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd6fec",
   "metadata": {},
   "source": [
    "#### Installation\n",
    "- conda create --name summit -c https://repo.anaconda.com/pkgs/snowflake python=3.8\n",
    "- conda activate summit\n",
    "- pip install \"snowflake-snowpark-python[pandas]==0.6.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21210110-09fb-41ed-a248-1ce6b1f21b47",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80562f60-bf0a-40cb-bd12-55f8066f595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import udf, count, col, year, call_udf, array_construct\n",
    "from snowflake.snowpark.types import Variant\n",
    "from snowflake.snowpark.version import VERSION\n",
    "# Misc\n",
    "import pandas as pd\n",
    "import json\n",
    "from cachetools import cached\n",
    "\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf9295-1fa3-4d77-8fb5-da71cab73475",
   "metadata": {},
   "source": [
    "### Creating Session object and connecting to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da9f106-f5b5-42a6-a341-22f282077484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse                   : SUMMIT_S\n",
      "Database                    : SUMMIT_DB\n",
      "Schema                      : SUMMIT_SCHEMA\n",
      "Snowflake version           : 6.18.2\n",
      "Snowpark for Python version : 0.7.0\n"
     ]
    }
   ],
   "source": [
    "connection_parameters = json.load(open('../connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "snowflake_environment = session.sql('select current_warehouse(), current_database(), current_schema(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('Warehouse                   : {}'.format(snowflake_environment[0][0]))\n",
    "print('Database                    : {}'.format(snowflake_environment[0][1]))\n",
    "print('Schema                      : {}'.format(snowflake_environment[0][2]))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][3]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a1f8e-7d9f-46fc-940e-85d0731e82b8",
   "metadata": {},
   "source": [
    "### Read data from Snowflake table and load it in Snowpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79dcb70b-4c34-47df-aef1-d26588d0af5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"MARKETPLACE\"  |\"REVIEW_ID\"     |\"PRODUCT_ID\"  |\"PRODUCT_PARENT\"  |\"PRODUCT_TITLE\"                                     |\"PRODUCT_CATEGORY\"  |\"STAR_RATING\"  |\"HELPFUL_VOTES\"  |\"TOTAL_VOTES\"  |\"VINE\"  |\"VERIFIED_PURCHASE\"  |\"REVIEW_HEADLINE\"                                   |\"REVIEW_BODY\"                                       |\"REVIEW_DATE\"  |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|US             |R3AVOU7PVQ69P3  |B000002GZ1    |375626671         |Paul Butterfield Blues Band                         |Music               |5              |2                |3              |N       |N                    |harmonica virtuoso                                  |the band is loaded with talent -- Butterfield, ...  |1998-11-14     |\n",
      "|US             |R2BO89LS9BDRYQ  |B00000AFWW    |973545513         |Celebrity Skin                                      |Music               |5              |0                |0              |N       |N                    |Makeover or no, Courtney kicks ass                  |As good as Live Through This, albeit with a mor...  |1998-11-14     |\n",
      "|US             |R304UT6ISP0ENK  |0140277447    |803730078         |The Rape of Nanking: The Forgotten Holocaust of...  |Books               |4              |137              |145            |N       |N                    |A forgotten holocause                               |I could not read Iris Chang's The Rape of Nanki...  |1998-11-14     |\n",
      "|US             |R8B77W3X913XH   |B000001DZQ    |33677664          |Sweet Dreams: Anthology                             |Music               |5              |0                |0              |N       |N                    |Roy was an un-sung Guitar Hero. He was definate...  |Roy Buchanan was such an influence to the great...  |1998-11-14     |\n",
      "|US             |R10GB3VQSD14KR  |B000002BBY    |370206005         |(What's The Story) Morning Glory?                   |Music               |1              |4                |17             |N       |N                    |One of the worst...                                 |There's no way to put it any milder.  I've list...  |1998-11-15     |\n",
      "|US             |R2W6ISZKV1P1OS  |B0000021RG    |835546146         |Live at Carnegie Hall                               |Music               |2              |4                |7              |N       |N                    |Do yourself a favor, avoid this CD                  |This CD, while very comprehensive, is woeful to...  |1998-11-15     |\n",
      "|US             |R1HBXTIBO1EH83  |B000002UAO    |4895975           |Rubber Soul (1990)                                  |Music               |5              |1                |1              |N       |N                    |Beatles at their best!                              |I can clearly remember listening to this album ...  |1998-11-15     |\n",
      "|US             |R3JZB9X4AZOQ07  |B000002NJS    |107731981         |Ray of Light                                        |Music               |5              |1                |1              |N       |N                    |Madonna's best work, her masterpiece...a work o...  |This is hands down the best album of 1998...of ...  |1998-11-15     |\n",
      "|US             |R2UCGBDCYT62P7  |0812550706    |401439625         |Ender's Game (The Ender Quintet)                    |Books               |5              |0                |0              |N       |N                    |Excellent read.                                     |You cannot claim to be a sci-fi enthusiast with...  |1998-11-15     |\n",
      "|US             |R3474GI5TL8R8K  |B000002BQK    |980911850         |Butterfly                                           |Music               |5              |0                |0              |N       |N                    |somebody finally shook some sense into her          |This CD is the third CD of Mariah's I own.  Tha...  |1998-11-15     |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df = session.table(\"SUMMIT_AMAZON_REVIEWS_DB.DASH_SCHEMA.AMAZON_REVIEWS\")\n",
    "snow_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd56c3a-75a6-4166-b940-4d65d512d2f2",
   "metadata": {},
   "source": [
    "### EDA -- Number of records per STAR_RATING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da3775a-a8ea-4398-b93f-676a1fa1422c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|\"STAR_RATING\"  |\"COUNT(STAR_RATING)\"  |\n",
      "----------------------------------------\n",
      "|5              |16697                 |\n",
      "|1              |1709                  |\n",
      "|4              |3827                  |\n",
      "|2              |1155                  |\n",
      "|3              |1612                  |\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df.group_by('STAR_RATING').agg(count('STAR_RATING')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed13bd",
   "metadata": {},
   "source": [
    "### EDA -- Number of records per PRODUCT_CATEGORY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41315521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "|\"PRODUCT_CATEGORY\"  |\"COUNT(PRODUCT_CATEGORY)\"  |\n",
      "--------------------------------------------------\n",
      "|Video               |1751                       |\n",
      "|Music               |5888                       |\n",
      "|Watches             |5000                       |\n",
      "|Books               |6640                       |\n",
      "|Camera              |5000                       |\n",
      "|Video DVD           |721                        |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df.group_by('PRODUCT_CATEGORY').agg(count('PRODUCT_CATEGORY')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71314391-e130-44fe-b3dc-f2a8be023e4c",
   "metadata": {},
   "source": [
    "### EDA -- Number of STAR_RATINGs per YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3b1acf-0ee8-49cf-84b3-9a7b8d7b2f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "|\"YEAR\"  |\"TOTAL_RATINGS\"  |\n",
      "----------------------------\n",
      "|1995    |9                |\n",
      "|1996    |192              |\n",
      "|1997    |1753             |\n",
      "|1998    |11274            |\n",
      "|1999    |1772             |\n",
      "|2015    |10000            |\n",
      "----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df.group_by(year('REVIEW_DATE')).agg(count('STAR_RATING').as_('TOTAL_RATINGS')).with_column_renamed('YEAR(REVIEW_DATE)','YEAR').sort('YEAR').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf78ccc-3132-42a7-b029-c26d89abdb9d",
   "metadata": {},
   "source": [
    "### EDA -- Missing data ... rows with no STAR_RATING or REVIEW_BODY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8380095-9ced-4e08-b6f4-fc9686123007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "|\"REVIEW_ID\"     |\"STAR_RATING\"  |\"REVIEW_BODY\"  |\n",
      "--------------------------------------------------\n",
      "|R3R885VN6USBYM  |5              |NULL           |\n",
      "|R3GKZOOU9MQIB8  |5              |NULL           |\n",
      "|R26LKY7Y8QG2Y2  |1              |NULL           |\n",
      "|R3QXY2UIFIUEYI  |4              |NULL           |\n",
      "|R2OJE1F0QFYC8E  |5              |NULL           |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df.filter(col('STAR_RATING').is_null() | col('REVIEW_BODY').is_null()).select(['REVIEW_ID','STAR_RATING','REVIEW_BODY']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086b6a2-a017-4717-bf48-f07157536a0b",
   "metadata": {},
   "source": [
    "### Data cleanup -- Remove rows with null values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b86b88fd-7471-4e34-8698-3e5540313b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records before cleanup    :  25000\n",
      "Records after cleanup     :  24994\n",
      "Number of records removed :  6\n"
     ]
    }
   ],
   "source": [
    "records_before = snow_df.count()\n",
    "print('Records before cleanup    : ',records_before)\n",
    "\n",
    "# Delete rows with missing values\n",
    "snow_df = snow_df.dropna()\n",
    "\n",
    "# Filter out rows with no STAR_RATING or REVIEW_BODY\n",
    "snow_df = snow_df.filter(col('STAR_RATING').is_not_null() | col('REVIEW_BODY').is_not_null())\n",
    "\n",
    "records_after = snow_df.count()\n",
    "print('Records after cleanup     : ',records_after)\n",
    "print('Number of records removed : ',(records_before - records_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b8865-af18-4b1c-b4b3-8f45d73375a3",
   "metadata": {},
   "source": [
    "### User-Defined Function (UDF) -- with dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fb54bb-80ba-49f8-a584-3fbbf0afc9ed",
   "metadata": {},
   "source": [
    "* Upload external dependency to an internal stage\n",
    "* Add dependency to the Session for the UDF\n",
    "* Create UDF with additional packages from Snowflake Anaconda Channel\n",
    "* Call UDF on Amaxon Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87dfc422-fdd9-4432-ad7d-a077694146d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The version of package spacy in the local environment is 3.2.3, which does not fit the criteria for the requirement spacy==2.3.5. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "# Upload dependencies to a stage\n",
    "session.sql(\"create or replace stage dash_udf_imports\").collect()\n",
    "session.file.put(\"file:///Users/ddesai/en_core_web_sm.zip\", \"@dash_udf_imports/\")\n",
    "\n",
    "# Add dependency to the Session for the UDF\n",
    "session.clear_imports()\n",
    "session.add_import('@dash_udf_imports/en_core_web_sm.zip.gz')\n",
    "\n",
    "# Function to download and extract English pipeline in spaCy\n",
    "@cached(cache={})\n",
    "def extract_en_core_web_sm(input_file: str, output_dir: str)-> object:\n",
    "    import zipfile\n",
    "    import spacy\n",
    "            \n",
    "    with zipfile.ZipFile(input_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "        \n",
    "    # load and return the english language small model of spacy\n",
    "    nlp = spacy.load(output_dir + \"/en_core_web_sm/en_core_web_sm-2.3.0\")\n",
    "    return nlp \n",
    "\n",
    "# Create UDF with additional packages from Snowflake Anaconda Channel\n",
    "# -- Remove HTML, tokenize text, lemmatize verbs and remove stop words\n",
    "@udf(name='process_text',session=session,packages=['spacy==2.3.5','beautifulsoup4','cachetools==4.2.2'],replace=True,is_permanent=True,stage_location='dash_udfs')\n",
    "def process_text(text: str) -> str:\n",
    "    import os\n",
    "    import sys\n",
    "    from bs4 import BeautifulSoup \n",
    "    from spacy.tokenizer import Tokenizer\n",
    "                       \n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "    \n",
    "    input_file = import_dir + 'en_core_web_sm.zip'\n",
    "    output_dir = '/tmp/en_core_web_sm' + str(os.getpid())\n",
    "    \n",
    "    nlp = extract_en_core_web_sm(input_file,output_dir)\n",
    "    stop_words = nlp.Defaults.stop_words\n",
    "    tokenizer = Tokenizer(nlp.vocab)\n",
    "    \n",
    "    # strip html\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # tokenize\n",
    "    tokens = tokenizer(text)\n",
    "    \n",
    "    # lemmatize verbs and remove stop words\n",
    "    text = [str(t.lemma_) for t in tokens if (t.orth_) not in stop_words] \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58272f5",
   "metadata": {},
   "source": [
    "### Call UDF on Amazon Reviews -- convert results into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed1e8a34-f092-4b0b-96c3-798cbf0af26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.76 ms, sys: 1.74 ms, total: 8.51 ms\n",
      "Wall time: 2.27 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW_BODY</th>\n",
       "      <th>PROCESSED_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ok</td>\n",
       "      <td>['okay']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perfect, even sturdier than the original!</td>\n",
       "      <td>['Perfect,', 'sturdy', 'original!']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If the words, &amp;#34;Cheap Chinese Junk&amp;#34; come to your mind when you see this, then congratulate yourself.  You're pretty close.  One of the most important features of a 'security camera&amp;#34; is the ability to detect motion and record, especially when running on battery and limited storage space.  I tested the motion detect on this camera in a few different environments so far (i.e. low light...</td>\n",
       "      <td>['If', 'words,', '\"Cheap', 'Chinese', 'Junk\"', 'come', 'mind', 'this,', 'congratulate', 'yourself.', ' ', \"You're\", 'pretty', 'close.', ' ', 'One', 'important', 'feature', \"'security\", 'camera\"', 'ability', 'detect', 'motion', 'record,', 'especially', 'run', 'battery', 'limit', 'storage', 'space.', ' ', 'I', 'test', 'motion', 'detect', 'camera', 'different', 'environment', 'far', '(i.e.', 'low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exactly what I wanted and expected. Perfect for hiking or carrying when you are going someplace you MAY need a quick closeup. I bought it to leave in my glovebox so I always have it with me. I've used it a few times already and couldn't be happier with it. For the price, it's definitely worth picking up if you are looking for a good monocular.</td>\n",
       "      <td>['Exactly', 'I', 'want', 'expected.', 'Perfect', 'hike', 'carry', 'go', 'someplace', 'MAY', 'need', 'quick', 'closeup.', 'I', 'buy', 'leave', 'glovebox', 'I', 'me.', \"I've\", 'time', \"couldn't\", 'happy', 'it.', 'For', 'price,', \"it's\", 'definitely', 'worth', 'pick', 'look', 'good', 'monocular.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I will look past the fact that they tricked me into believing this is a Canon product. It's not by Canon. It's some generic brand that i've never heard of. HOWEVER, it works surprisingly well! The sound quality is actually really good. The wire is actually super long and is perfect for indoor shooting.</td>\n",
       "      <td>['I', 'look', 'past', 'fact', 'trick', 'believe', 'Canon', 'product.', \"It's\", 'Canon.', \"It's\", 'generic', 'brand', \"i've\", 'hear', 'of.', 'HOWEVER,', 'work', 'surprisingly', 'well!', 'The', 'sound', 'quality', 'actually', 'good.', 'The', 'wire', 'actually', 'super', 'long', 'perfect', 'indoor', 'shooting.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                       REVIEW_BODY  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                               ok   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                        Perfect, even sturdier than the original!   \n",
       "2  If the words, &#34;Cheap Chinese Junk&#34; come to your mind when you see this, then congratulate yourself.  You're pretty close.  One of the most important features of a 'security camera&#34; is the ability to detect motion and record, especially when running on battery and limited storage space.  I tested the motion detect on this camera in a few different environments so far (i.e. low light...   \n",
       "3                                                        Exactly what I wanted and expected. Perfect for hiking or carrying when you are going someplace you MAY need a quick closeup. I bought it to leave in my glovebox so I always have it with me. I've used it a few times already and couldn't be happier with it. For the price, it's definitely worth picking up if you are looking for a good monocular.   \n",
       "4                                                                                                  I will look past the fact that they tricked me into believing this is a Canon product. It's not by Canon. It's some generic brand that i've never heard of. HOWEVER, it works surprisingly well! The sound quality is actually really good. The wire is actually super long and is perfect for indoor shooting.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                    PROCESSED_TEXT  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                         ['okay']  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                              ['Perfect,', 'sturdy', 'original!']  \n",
       "2  ['If', 'words,', '\"Cheap', 'Chinese', 'Junk\"', 'come', 'mind', 'this,', 'congratulate', 'yourself.', ' ', \"You're\", 'pretty', 'close.', ' ', 'One', 'important', 'feature', \"'security\", 'camera\"', 'ability', 'detect', 'motion', 'record,', 'especially', 'run', 'battery', 'limit', 'storage', 'space.', ' ', 'I', 'test', 'motion', 'detect', 'camera', 'different', 'environment', 'far', '(i.e.', 'low...  \n",
       "3                                                                                                          ['Exactly', 'I', 'want', 'expected.', 'Perfect', 'hike', 'carry', 'go', 'someplace', 'MAY', 'need', 'quick', 'closeup.', 'I', 'buy', 'leave', 'glovebox', 'I', 'me.', \"I've\", 'time', \"couldn't\", 'happy', 'it.', 'For', 'price,', \"it's\", 'definitely', 'worth', 'pick', 'look', 'good', 'monocular.']  \n",
       "4                                                                                           ['I', 'look', 'past', 'fact', 'trick', 'believe', 'Canon', 'product.', \"It's\", 'Canon.', \"It's\", 'generic', 'brand', \"i've\", 'hear', 'of.', 'HOWEVER,', 'work', 'surprisingly', 'well!', 'The', 'sound', 'quality', 'actually', 'good.', 'The', 'wire', 'actually', 'super', 'long', 'perfect', 'indoor', 'shooting.']  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_amazon_reviews = snow_df.limit(10).select('REVIEW_BODY', call_udf(\"process_text\", col(\"REVIEW_BODY\")).as_('PROCESSED_TEXT')).to_pandas()\n",
    "df_amazon_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e59b4-4ce7-4728-aa44-935d6539b2c2",
   "metadata": {},
   "source": [
    "### Model Training using scikit-learn in Stored Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8afc0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.7</td>\n",
       "      <td>48.9</td>\n",
       "      <td>75.0</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.5</td>\n",
       "      <td>32.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>120.2</td>\n",
       "      <td>19.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>199.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>21.2</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3   12.0\n",
       "3  151.5   41.3       58.5   16.5\n",
       "4  180.8   10.8       58.4   17.9\n",
       "5    8.7   48.9       75.0    7.2\n",
       "6   57.5   32.8       23.5   11.8\n",
       "7  120.2   19.6       11.6   13.2\n",
       "8    8.6    2.1        1.0    4.8\n",
       "9  199.8    2.6       21.2   15.6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_budgets = pd.read_csv('advertising.csv')\n",
    "df_budgets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbd815ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sales_prediction_model(session: Session, features_table: str) -> Variant:\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "    import os\n",
    "    from joblib import dump\n",
    "\n",
    "    df = pd.read_csv(features_table)\n",
    "\n",
    "    # Preprocess the Numeric columns\n",
    "    # We apply PolynomialFeatures and StandardScaler preprocessing steps to the numeric columns. NOTE: High degrees can cause overfitting.\n",
    "    numeric_features = ['TV','Radio','Newspaper']\n",
    "    numeric_transformer = Pipeline(steps=[('poly',PolynomialFeatures(degree = 2)),('scaler', StandardScaler())])\n",
    "\n",
    "    # Combine the preprocessed step together using the Column Transformer module\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)])\n",
    "\n",
    "    # The next step is the integrate the features we just preprocessed with our Machine Learning algorithm to enable us to build a model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),('classifier', LinearRegression())])\n",
    "    parameteres = {}\n",
    "\n",
    "    X = df.drop('Sales', axis = 1)\n",
    "    y = df['Sales']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "    model = GridSearchCV(pipeline, param_grid=parameteres, cv=10)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Upload trained model to a stage\n",
    "    model_output_dir = '/tmp'\n",
    "    model_file = os.path.join(model_output_dir, 'sales_model.joblib')\n",
    "    dump(model, model_file)\n",
    "    session.file.put(model_file, \"@dash_models\",overwrite=True)\n",
    "\n",
    "    # Return model R2 score on train and test data\n",
    "    return {\"R2 score on Train\": model.score(X_train, y_train),\"R2 score on Test\": model.score(X_test, y_test)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d54f8b-8021-4065-a316-32b344b3386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R2 score on Train': 0.9288133512730626, 'R2 score on Test': 0.9533174341074796}\n"
     ]
    }
   ],
   "source": [
    "print(train_sales_prediction_model(session,\"advertising.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be255759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.stored_procedure.StoredProcedure at 0x7fcd405663d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sproc.register(func=train_sales_prediction_model,name=\"train_sales_prediction_model\",packages=['snowflake-snowpark-python','scikit-learn','joblib'],is_permanent=True,stage_location=\"@dash_sprocs\",replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eae5d98c-ab01-4b9d-bb58-00be7a22041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "\n",
    "# Add trained model as dependency\n",
    "session.add_import('@dash_models/sales_model.joblib.gz')\n",
    "\n",
    "@udf(name='predict_sales',session=session,packages=['pandas','joblib','scikit-learn'],replace=True,is_permanent=True,stage_location='@dash_udfs')\n",
    "def predict_sales(budget_allocations: list) -> float:\n",
    "    import sys\n",
    "    import pandas as pd\n",
    "    from joblib import load\n",
    "\n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "    \n",
    "    model_file = import_dir + 'sales_model.joblib.gz'\n",
    "\n",
    "    model = load(model_file)\n",
    "            \n",
    "    features = ['TV','Radio','Newspaper']\n",
    "    df = pd.DataFrame([budget_allocations], columns=features)\n",
    "    sales = round(model.predict(df)[0],2)\n",
    "\n",
    "    return sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a60f1b28-d4c9-435e-8455-271609a507c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "|\"TV\"   |\"RADIO\"  |\"NEWSPAPER\"  |\"PREDICTED_SALES\"  |\n",
      "-----------------------------------------------------\n",
      "|120.2  |19.6     |11.6         |13.69              |\n",
      "|180.8  |10.8     |58.4         |16.13              |\n",
      "|199.8  |2.6      |21.2         |16.2               |\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = session.create_dataframe([[180.8,10.8,58.4],[120.2,19.6,11.6],[199.8,2.6,21.2]], schema=['TV','Radio','Newspaper'])\n",
    "test_df.select('TV','Radio','Newspaper', \n",
    "    call_udf(\"predict_sales\", array_construct(col(\"TV\"), col(\"Radio\"), col(\"Newspaper\"))).as_(\"PREDICTED_SALES\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844b407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fb0a37530c0004d75c43dbcefc0b8b6ea2fdc6f87c96f7fd6f8cf43b3f551c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('snowpark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
