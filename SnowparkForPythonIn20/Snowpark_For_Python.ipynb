{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3622d34c-dd6f-410d-8196-f5884bd7836a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Snowpark For Python\n",
    "\n",
    "### In this session, we will cover:\n",
    "\n",
    "* Snowpark for Python Installation\n",
    "* Creating Session object and connecting to Snowflake\n",
    "* Reading and loading data from Snowflake table into Snowpark DataFrame\n",
    "* Perfoming Exploratory Data Analysis (EDA) on Snowpark DataFrame\n",
    "* Creating User-Defined Function (UDF)\n",
    "* Using pre-trained scikit-learn model for inference in UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd6fec",
   "metadata": {},
   "source": [
    "### Snowpark For Python Installation\n",
    "- conda create --name snowpark -c https://repo.anaconda.com/pkgs/snowflake python=3.8\n",
    "- conda activate snowpark\n",
    "- pip install \"snowflake-snowpark-python[pandas]\"\n",
    "- pip install ipykernel\n",
    "- pip install cachetools\n",
    "- pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21210110-09fb-41ed-a248-1ce6b1f21b47",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80562f60-bf0a-40cb-bd12-55f8066f595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import udf, count, col, year, call_udf, array_construct\n",
    "from snowflake.snowpark.types import Variant\n",
    "from snowflake.snowpark.version import VERSION\n",
    "# Misc\n",
    "import pandas as pd\n",
    "import json\n",
    "from cachetools import cached\n",
    "\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf9295-1fa3-4d77-8fb5-da71cab73475",
   "metadata": {},
   "source": [
    "### Establish Secure Connection to Snowflake\n",
    "\n",
    "##### *Options: Username/Password, MFA, OAuth, Okta, SSO*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2da9f106-f5b5-42a6-a341-22f282077484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse                   : SUMMIT_S\n",
      "Database                    : SUMMIT_DB\n",
      "Schema                      : SUMMIT_SCHEMA\n",
      "Snowflake version           : 6.18.3\n",
      "Snowpark for Python version : 0.7.0\n"
     ]
    }
   ],
   "source": [
    "connection_parameters = json.load(open('../connection.json'))\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "snowflake_environment = session.sql('select current_warehouse(), current_database(), current_schema(), current_version()').collect()\n",
    "snowpark_version = VERSION\n",
    "\n",
    "# Current Environment Details\n",
    "print('Warehouse                   : {}'.format(snowflake_environment[0][0]))\n",
    "print('Database                    : {}'.format(snowflake_environment[0][1]))\n",
    "print('Schema                      : {}'.format(snowflake_environment[0][2]))\n",
    "print('Snowflake version           : {}'.format(snowflake_environment[0][3]))\n",
    "print('Snowpark for Python version : {}.{}.{}'.format(snowpark_version[0],snowpark_version[1],snowpark_version[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a1f8e-7d9f-46fc-940e-85d0731e82b8",
   "metadata": {},
   "source": [
    "### Load Amazon Reviews data from Snowflake table into Snowpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79dcb70b-4c34-47df-aef1-d26588d0af5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|\"MARKETPLACE\"  |\"REVIEW_ID\"     |\"PRODUCT_ID\"  |\"PRODUCT_PARENT\"  |\"PRODUCT_TITLE\"                                     |\"PRODUCT_CATEGORY\"  |\"STAR_RATING\"  |\"HELPFUL_VOTES\"  |\"TOTAL_VOTES\"  |\"VINE\"  |\"VERIFIED_PURCHASE\"  |\"REVIEW_HEADLINE\"                                   |\"REVIEW_BODY\"                                       |\"REVIEW_DATE\"  |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|US             |R2W9DA68EPF0FV  |0679433740    |925934976         |Paradise                                            |Books               |3              |0                |1              |N       |N                    |complex but enjoyable                               |I read this book for a book club assignment.  I...  |1998-07-06     |\n",
      "|US             |R2PQMUNTNC11BT  |0670880728    |738261988         |Bridget Jones's Diary                               |Books               |5              |1                |1              |N       |N                    |When are they bringing out Diary #2?  Keep 'em ...  |I thought that Bridget was so completely and ut...  |1998-07-06     |\n",
      "|US             |R1H3J29NUX6YV0  |0060920084    |754387444         |The Lost Continent: Travels in Small-Town America   |Books               |3              |5                |7              |N       |N                    |Clever but cruel                                    |Bryson's breakneck tour through small American ...  |1998-07-06     |\n",
      "|US             |R16TBQZL8TQTO2  |0553208845    |36215520          |Siddhartha                                          |Books               |5              |0                |0              |N       |N                    |A Beautiful Story                                   |This book is so wonderfully written that it tak...  |1998-07-06     |\n",
      "|US             |RW3PHHVONKQRK   |B000006NPY    |940428624         |Adore                                               |Music               |4              |0                |0              |N       |N                    |You'll adore it!                                    |It's different from the other cd's, but it's a ...  |1998-07-06     |\n",
      "|US             |R1SU6AE9W0XRNU  |B000002N2P    |820995200         |Green Day - Insomniac                               |Music               |1              |3                |22             |N       |N                    |I wish I could give it ZERO stars                   |This album is a discrace to music.  It is a dis...  |1998-07-07     |\n",
      "|US             |R5IT6PFPOFYTO   |B000002NHN    |95315084          |The Book of Secrets                                 |Music               |5              |0                |0              |N       |N                    |Even in michigan, we love it                        |Loreena McKennitt does it again with a compilat...  |1998-07-07     |\n",
      "|US             |RL790PTSRIVWA   |0783880871    |529898130         |Unnatural Exposure                                  |Books               |1              |0                |0              |N       |N                    |A sloppy effort, too many loose ends.. unsatisf...  |Half a star would do actually ... PC tries to i...  |1998-07-07     |\n",
      "|US             |R17DHSAWYNIBD7  |B000002LIM    |375271481         |Batman: Original Motion Picture Score               |Music               |5              |2                |2              |N       |N                    |One of the All-Time Great Movie Themes              |Danny Elfman has composed a wonderfully origina...  |1998-07-07     |\n",
      "|US             |R2FEX1S8FAHSDZ  |0887306667    |381720534         |The 22 Immutable Laws of Marketing:  Violate Th...  |Books               |4              |1                |1              |N       |N                    |The Marketing Cooking book                          |A well written book about classic marketing app...  |1998-07-07     |\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df = session.table(\"SUMMIT_AMAZON_REVIEWS_DB.DASH_SCHEMA.AMAZON_REVIEWS\")\n",
    "snow_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd56c3a-75a6-4166-b940-4d65d512d2f2",
   "metadata": {},
   "source": [
    "### Number of records per STAR_RATING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da3775a-a8ea-4398-b93f-676a1fa1422c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "|\"STAR_RATING\"  |\"COUNT(STAR_RATING)\"  |\n",
      "----------------------------------------\n",
      "|5              |16697                 |\n",
      "|1              |1709                  |\n",
      "|3              |1612                  |\n",
      "|2              |1155                  |\n",
      "|4              |3827                  |\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df.group_by('STAR_RATING').agg(count('STAR_RATING')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed13bd",
   "metadata": {},
   "source": [
    "### Number of records per PRODUCT_CATEGORY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41315521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "|\"PRODUCT_CATEGORY\"  |\"COUNT(PRODUCT_CATEGORY)\"  |\n",
      "--------------------------------------------------\n",
      "|Video               |1751                       |\n",
      "|Books               |6640                       |\n",
      "|Camera              |5000                       |\n",
      "|Video DVD           |721                        |\n",
      "|Music               |5888                       |\n",
      "|Watches             |5000                       |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df.group_by('PRODUCT_CATEGORY').agg(count('PRODUCT_CATEGORY')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71314391-e130-44fe-b3dc-f2a8be023e4c",
   "metadata": {},
   "source": [
    "### Number of STAR_RATINGs per YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3b1acf-0ee8-49cf-84b3-9a7b8d7b2f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "|\"YEAR\"  |\"TOTAL_RATINGS\"  |\n",
      "----------------------------\n",
      "|1995    |9                |\n",
      "|1996    |192              |\n",
      "|1997    |1753             |\n",
      "|1998    |11274            |\n",
      "|1999    |1772             |\n",
      "|2015    |10000            |\n",
      "----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df.group_by(year('REVIEW_DATE')).agg(count('STAR_RATING').as_('TOTAL_RATINGS')).with_column_renamed('YEAR(REVIEW_DATE)','YEAR').sort('YEAR').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf78ccc-3132-42a7-b029-c26d89abdb9d",
   "metadata": {},
   "source": [
    "### Missing data ... rows with no STAR_RATING or REVIEW_BODY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8380095-9ced-4e08-b6f4-fc9686123007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "|\"REVIEW_ID\"     |\"STAR_RATING\"  |\"REVIEW_BODY\"  |\n",
      "--------------------------------------------------\n",
      "|R3R885VN6USBYM  |5              |NULL           |\n",
      "|R3GKZOOU9MQIB8  |5              |NULL           |\n",
      "|R26LKY7Y8QG2Y2  |1              |NULL           |\n",
      "|R3QXY2UIFIUEYI  |4              |NULL           |\n",
      "|R2OJE1F0QFYC8E  |5              |NULL           |\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df = snow_df.filter(col('STAR_RATING').is_null() | col('REVIEW_BODY').is_null()).select(['REVIEW_ID','STAR_RATING','REVIEW_BODY'])\n",
    "temp_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa2fb0f",
   "metadata": {},
   "source": [
    "#### >>>>>>>>>> *Examine Snowpark DataFrame Query* <<<<<<<<<< "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d941dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'queries': ['SELECT \"REVIEW_ID\", \"STAR_RATING\", \"REVIEW_BODY\" FROM ( SELECT  *  FROM ( SELECT  *  FROM (SUMMIT_AMAZON_REVIEWS_DB.DASH_SCHEMA.AMAZON_REVIEWS)) WHERE (\"STAR_RATING\" IS NULL OR \"REVIEW_BODY\" IS NULL))'],\n",
       " 'post_actions': []}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086b6a2-a017-4717-bf48-f07157536a0b",
   "metadata": {},
   "source": [
    "### Data cleanup -- Remove rows with null values, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b86b88fd-7471-4e34-8698-3e5540313b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records before cleanup    :  25000\n",
      "Records after cleanup     :  24994\n",
      "Number of records removed :  6\n"
     ]
    }
   ],
   "source": [
    "records_before = snow_df.count()\n",
    "print('Records before cleanup    : ',records_before)\n",
    "\n",
    "# Delete rows with missing values\n",
    "snow_df = snow_df.dropna()\n",
    "\n",
    "# Filter out rows with no STAR_RATING or REVIEW_BODY\n",
    "snow_df = snow_df.filter(col('STAR_RATING').is_not_null() | col('REVIEW_BODY').is_not_null())\n",
    "\n",
    "records_after = snow_df.count()\n",
    "print('Records after cleanup     : ',records_after)\n",
    "print('Number of records removed : ',(records_before - records_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b8865-af18-4b1c-b4b3-8f45d73375a3",
   "metadata": {},
   "source": [
    "### User-Defined Function (UDF) for Text Processing Using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fb54bb-80ba-49f8-a584-3fbbf0afc9ed",
   "metadata": {},
   "source": [
    "* Upload external dependency to an internal stage\n",
    "* Add dependency to the Session for the UDF\n",
    "* Create UDF with additional packages from Snowflake Anaconda Channel\n",
    "* Call UDF on Amaxon Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87dfc422-fdd9-4432-ad7d-a077694146d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The version of package spacy in the local environment is 3.2.3, which does not fit the criteria for the requirement spacy==2.3.5. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "# Upload dependencies to a stage\n",
    "session.sql(\"create or replace stage dash_udf_imports\").collect()\n",
    "session.file.put(\"file:///Users/ddesai/en_core_web_sm.zip\", \"@dash_udf_imports/\")\n",
    "\n",
    "# Add dependency to the Session for the UDF\n",
    "session.clear_imports()\n",
    "session.add_import('@dash_udf_imports/en_core_web_sm.zip.gz')\n",
    "\n",
    "# Function to download and extract English pipeline in spaCy\n",
    "@cached(cache={})\n",
    "def extract_en_core_web_sm(input_file: str, output_dir: str)-> object:\n",
    "    import zipfile\n",
    "    import spacy\n",
    "            \n",
    "    with zipfile.ZipFile(input_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "        \n",
    "    # load and return the english language small model of spacy\n",
    "    nlp = spacy.load(output_dir + \"/en_core_web_sm/en_core_web_sm-2.3.0\")\n",
    "    return nlp \n",
    "\n",
    "# Create UDF with additional packages from Snowflake Anaconda Channel\n",
    "# -- Remove HTML, tokenize text, lemmatize verbs and remove stop words\n",
    "@udf(name='process_text',session=session,packages=['spacy==2.3.5','beautifulsoup4','cachetools==4.2.2'],replace=True,is_permanent=True,stage_location='dash_udfs')\n",
    "def process_text(text: str) -> str:\n",
    "    import os\n",
    "    import sys\n",
    "    from bs4 import BeautifulSoup \n",
    "    from spacy.tokenizer import Tokenizer\n",
    "                       \n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "    \n",
    "    input_file = import_dir + 'en_core_web_sm.zip'\n",
    "    output_dir = '/tmp/en_core_web_sm' + str(os.getpid())\n",
    "    \n",
    "    nlp = extract_en_core_web_sm(input_file,output_dir)\n",
    "    stop_words = nlp.Defaults.stop_words\n",
    "    tokenizer = Tokenizer(nlp.vocab)\n",
    "    \n",
    "    # strip html\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    \n",
    "    # tokenize\n",
    "    tokens = tokenizer(text)\n",
    "    \n",
    "    # lemmatize verbs and remove stop words\n",
    "    text = [str(t.lemma_) for t in tokens if (t.orth_) not in stop_words] \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2714de9b",
   "metadata": {},
   "source": [
    "### >>>>>>>>>> *Examine Query History in Snowsight* <<<<<<<<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58272f5",
   "metadata": {},
   "source": [
    "### Call UDF on Amazon Reviews -- optionally convert results into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed1e8a34-f092-4b0b-96c3-798cbf0af26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.91 ms, sys: 3.23 ms, total: 12.1 ms\n",
      "Wall time: 2.64 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW_BODY</th>\n",
       "      <th>PROCESSED_TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ok</td>\n",
       "      <td>['okay']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perfect, even sturdier than the original!</td>\n",
       "      <td>['Perfect,', 'sturdy', 'original!']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If the words, &amp;#34;Cheap Chinese Junk&amp;#34; come to your mind when you see this, then congratulate yourself.  You're pretty close.  One of the most important features of a 'security camera&amp;#34; is the ability to detect motion and record, especially when running on battery and limited storage space.  I tested the motion detect on this camera in a few different environments so far (i.e. low light...</td>\n",
       "      <td>['If', 'words,', '\"Cheap', 'Chinese', 'Junk\"', 'come', 'mind', 'this,', 'congratulate', 'yourself.', ' ', \"You're\", 'pretty', 'close.', ' ', 'One', 'important', 'feature', \"'security\", 'camera\"', 'ability', 'detect', 'motion', 'record,', 'especially', 'run', 'battery', 'limit', 'storage', 'space.', ' ', 'I', 'test', 'motion', 'detect', 'camera', 'different', 'environment', 'far', '(i.e.', 'low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exactly what I wanted and expected. Perfect for hiking or carrying when you are going someplace you MAY need a quick closeup. I bought it to leave in my glovebox so I always have it with me. I've used it a few times already and couldn't be happier with it. For the price, it's definitely worth picking up if you are looking for a good monocular.</td>\n",
       "      <td>['Exactly', 'I', 'want', 'expected.', 'Perfect', 'hike', 'carry', 'go', 'someplace', 'MAY', 'need', 'quick', 'closeup.', 'I', 'buy', 'leave', 'glovebox', 'I', 'me.', \"I've\", 'time', \"couldn't\", 'happy', 'it.', 'For', 'price,', \"it's\", 'definitely', 'worth', 'pick', 'look', 'good', 'monocular.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I will look past the fact that they tricked me into believing this is a Canon product. It's not by Canon. It's some generic brand that i've never heard of. HOWEVER, it works surprisingly well! The sound quality is actually really good. The wire is actually super long and is perfect for indoor shooting.</td>\n",
       "      <td>['I', 'look', 'past', 'fact', 'trick', 'believe', 'Canon', 'product.', \"It's\", 'Canon.', \"It's\", 'generic', 'brand', \"i've\", 'hear', 'of.', 'HOWEVER,', 'work', 'surprisingly', 'well!', 'The', 'sound', 'quality', 'actually', 'good.', 'The', 'wire', 'actually', 'super', 'long', 'perfect', 'indoor', 'shooting.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                       REVIEW_BODY  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                               ok   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                        Perfect, even sturdier than the original!   \n",
       "2  If the words, &#34;Cheap Chinese Junk&#34; come to your mind when you see this, then congratulate yourself.  You're pretty close.  One of the most important features of a 'security camera&#34; is the ability to detect motion and record, especially when running on battery and limited storage space.  I tested the motion detect on this camera in a few different environments so far (i.e. low light...   \n",
       "3                                                        Exactly what I wanted and expected. Perfect for hiking or carrying when you are going someplace you MAY need a quick closeup. I bought it to leave in my glovebox so I always have it with me. I've used it a few times already and couldn't be happier with it. For the price, it's definitely worth picking up if you are looking for a good monocular.   \n",
       "4                                                                                                  I will look past the fact that they tricked me into believing this is a Canon product. It's not by Canon. It's some generic brand that i've never heard of. HOWEVER, it works surprisingly well! The sound quality is actually really good. The wire is actually super long and is perfect for indoor shooting.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                    PROCESSED_TEXT  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                         ['okay']  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                              ['Perfect,', 'sturdy', 'original!']  \n",
       "2  ['If', 'words,', '\"Cheap', 'Chinese', 'Junk\"', 'come', 'mind', 'this,', 'congratulate', 'yourself.', ' ', \"You're\", 'pretty', 'close.', ' ', 'One', 'important', 'feature', \"'security\", 'camera\"', 'ability', 'detect', 'motion', 'record,', 'especially', 'run', 'battery', 'limit', 'storage', 'space.', ' ', 'I', 'test', 'motion', 'detect', 'camera', 'different', 'environment', 'far', '(i.e.', 'low...  \n",
       "3                                                                                                          ['Exactly', 'I', 'want', 'expected.', 'Perfect', 'hike', 'carry', 'go', 'someplace', 'MAY', 'need', 'quick', 'closeup.', 'I', 'buy', 'leave', 'glovebox', 'I', 'me.', \"I've\", 'time', \"couldn't\", 'happy', 'it.', 'For', 'price,', \"it's\", 'definitely', 'worth', 'pick', 'look', 'good', 'monocular.']  \n",
       "4                                                                                           ['I', 'look', 'past', 'fact', 'trick', 'believe', 'Canon', 'product.', \"It's\", 'Canon.', \"It's\", 'generic', 'brand', \"i've\", 'hear', 'of.', 'HOWEVER,', 'work', 'surprisingly', 'well!', 'The', 'sound', 'quality', 'actually', 'good.', 'The', 'wire', 'actually', 'super', 'long', 'perfect', 'indoor', 'shooting.']  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_amazon_reviews = snow_df.limit(10).select('REVIEW_BODY', call_udf(\"process_text\", col(\"REVIEW_BODY\")).as_('PROCESSED_TEXT')).to_pandas()\n",
    "df_amazon_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e59b4-4ce7-4728-aa44-935d6539b2c2",
   "metadata": {},
   "source": [
    "### Model Training in Snowflake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5ce0bc",
   "metadata": {},
   "source": [
    "#### Load Advertising Data into Snowpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79d9ff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "|\"TV\"   |\"Radio\"  |\"Newspaper\"  |\"Sales\"  |\n",
      "-------------------------------------------\n",
      "|230.1  |37.8     |69.2         |22.1     |\n",
      "|44.5   |39.3     |45.1         |10.4     |\n",
      "|17.2   |45.9     |69.3         |12.0     |\n",
      "|151.5  |41.3     |58.5         |16.5     |\n",
      "|180.8  |10.8     |58.4         |17.9     |\n",
      "|8.7    |48.9     |75.0         |7.2      |\n",
      "|57.5   |32.8     |23.5         |11.8     |\n",
      "|120.2  |19.6     |11.6         |13.2     |\n",
      "|8.6    |2.1      |1.0          |4.8      |\n",
      "|199.8  |2.6      |21.2         |15.6     |\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snow_df_budgets = session.table('ADVERTISING_BUDGETS')\n",
    "snow_df_budgets.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a040d4b",
   "metadata": {},
   "source": [
    "#### Snowpark Python code to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbd815ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sales_prediction_model(session: Session, features_table: str) -> Variant:\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "    import os\n",
    "    from joblib import dump\n",
    "\n",
    "    # Load features\n",
    "    df = session.table(features_table).to_pandas()\n",
    "\n",
    "    # Preprocess the Numeric columns\n",
    "    # We apply PolynomialFeatures and StandardScaler preprocessing steps to the numeric columns. NOTE: High degrees can cause overfitting.\n",
    "    numeric_features = ['TV','Radio','Newspaper']\n",
    "    numeric_transformer = Pipeline(steps=[('poly',PolynomialFeatures(degree = 2)),('scaler', StandardScaler())])\n",
    "\n",
    "    # Combine the preprocessed step together using the Column Transformer module\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)])\n",
    "\n",
    "    # The next step is the integrate the features we just preprocessed with our Machine Learning algorithm to enable us to build a model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),('classifier', LinearRegression())])\n",
    "    parameteres = {}\n",
    "\n",
    "    X = df.drop('Sales', axis = 1)\n",
    "    y = df['Sales']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "    model = GridSearchCV(pipeline, param_grid=parameteres, cv=10)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Upload trained model to a stage\n",
    "    model_output_dir = '/tmp'\n",
    "    model_file = os.path.join(model_output_dir, 'sales_model.joblib')\n",
    "    dump(model, model_file)\n",
    "    session.file.put(model_file, \"@dash_models\",overwrite=True)\n",
    "\n",
    "    # Return model R2 score on train and test data\n",
    "    return {\"R2 score on Train\": model.score(X_train, y_train),\"R2 score on Test\": model.score(X_test, y_test)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a9048d",
   "metadata": {},
   "source": [
    "#### Test Python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77d54f8b-8021-4065-a316-32b344b3386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R2 score on Train': 0.9288133512730626, 'R2 score on Test': 0.9533174341074796}\n"
     ]
    }
   ],
   "source": [
    "print(train_sales_prediction_model(session,\"ADVERTISING_BUDGETS\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22263505",
   "metadata": {},
   "source": [
    "### Create Stored Procedure to deploy training code on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be255759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.stored_procedure.StoredProcedure at 0x7f9ad8beb220>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sproc.register(func=train_sales_prediction_model,name=\"train_sales_prediction_model\",packages=['snowflake-snowpark-python','scikit-learn','joblib'],is_permanent=True,stage_location=\"@dash_sprocs\",replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba80e514",
   "metadata": {},
   "source": [
    "### Execute Stored Procedure to train model and deploy it on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca9b909c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"R2 score on Test\": 0.9533174341074796,\n",
      "  \"R2 score on Train\": 0.9288133512730626\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(session.call('train_sales_prediction_model','ADVERTISING_BUDGETS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3bc57",
   "metadata": {},
   "source": [
    "### >>>>>>>>>> *Examine Query History in Snowsight* <<<<<<<<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d4fc0",
   "metadata": {},
   "source": [
    "### Create User-Defined Function for Inference on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eae5d98c-ab01-4b9d-bb58-00be7a22041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "\n",
    "# Add trained model as dependency\n",
    "session.add_import('@dash_models/sales_model.joblib.gz')\n",
    "\n",
    "@udf(name='predict_sales',session=session,packages=['pandas','joblib','scikit-learn'],replace=True,is_permanent=True,stage_location='@dash_udfs')\n",
    "def predict_sales(budget_allocations: list) -> float:\n",
    "    import sys\n",
    "    import pandas as pd\n",
    "    from joblib import load\n",
    "\n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "    \n",
    "    model_file = import_dir + 'sales_model.joblib.gz'\n",
    "\n",
    "    model = load(model_file)\n",
    "            \n",
    "    features = ['TV','Radio','Newspaper']\n",
    "    df = pd.DataFrame([budget_allocations], columns=features)\n",
    "    sales = round(model.predict(df)[0],2)\n",
    "\n",
    "    return sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a60f1b28-d4c9-435e-8455-271609a507c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "|\"TV\"   |\"RADIO\"  |\"NEWSPAPER\"  |\"PREDICTED_SALES\"  |\n",
      "-----------------------------------------------------\n",
      "|180.8  |10.8     |58.4         |16.13              |\n",
      "|199.8  |2.6      |21.2         |16.2               |\n",
      "|120.2  |19.6     |11.6         |13.69              |\n",
      "-----------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = session.create_dataframe([[180.8,10.8,58.4],[120.2,19.6,11.6],[199.8,2.6,21.2]], schema=['TV','Radio','Newspaper'])\n",
    "test_df.select('TV','Radio','Newspaper', \n",
    "    call_udf(\"predict_sales\", array_construct(col(\"TV\"), col(\"Radio\"), col(\"Newspaper\"))).as_(\"PREDICTED_SALES\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5dfd4",
   "metadata": {},
   "source": [
    "### >>>>>>>>>> *Examine Query History in Snowsight* <<<<<<<<<<"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62291ee0",
   "metadata": {},
   "source": [
    "# Code on GitHub\n",
    "\n",
    "### Python Notebook is available at https://github.com/iamontheinet/dash-at-summit-2020"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fb0a37530c0004d75c43dbcefc0b8b6ea2fdc6f87c96f7fd6f8cf43b3f551c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('snowpark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
